pr: none

pool: 'NHT Ubuntu 18.04 v2'

parameters:
  - name: ScalaVersion
    displayName: Version of libraries to build, should match 
    type: string
    default: "2.12" # Databricks 9.1 LTS
  - name: SparkVersion
    displayName: Version of libraries to build, should match 
    type: string
    default: "3.1.2" # Databricks 9.1 LTS

stages:
- stage: BuildPublishSparkListenerJars
  displayName: Build Pyspark Dev Image if Needed
  jobs:
  - job: BuildPublishJARs
    steps:
    - script: |
        docker run --rm -v "$(pwd):/spark-monitoring" -w /spark-monitoring/src mcr.microsoft.com/java/maven:8-zulu-debian10 mvn install -P "scala-${{ parameters.ScalaVersion }}_spark-${{ parameters.SparkVersion }}"
      displayName: Build jars in docker image

    - script: |
        pwd
        ls -l $(Pipeline.Workspace)
        ls -l $(Pipeline.Workspace)/s
        ls -l $(Pipeline.Workspace)/s/src
        ls -l $(Pipeline.Workspace)/s/src/target

    - task: UniversalPackages@0
      displayName: Universal Publish Spark-Listeners
      continueOnError: true
      inputs:
        command: 'publish'
        publishDirectory: '$(Pipeline.Workspace)/s/src/target'
        feedsToUsePublish: 'internal'
        vstsFeedPublish: '3c59b87f-2432-4abe-afde-e4027aeaadf8'
        vstsFeedPackagePublish: 'spark-listeners_${{ parameters.SparkVersion }}_${{ parameters.ScalaVersion }}-1.0.0.jar'
        versionOption: major
        packagePublishDescription: 'NHT Custom Log Analytic JARs'
    - task: UniversalPackages@0
      displayName: Universal Publish Spark-Listeners
      continueOnError: true
      inputs:
        command: 'publish'
        publishDirectory: '$(Pipeline.Workspace)/s/src/target/spark-listeners_${{ parameters.SparkVersion }}_${{ parameters.ScalaVersion }}-1.0.0.jar'
        feedsToUsePublish: 'internal'
        vstsFeedPublish: '3c59b87f-2432-4abe-afde-e4027aeaadf8'
        vstsFeedPackagePublish: 'spark-listeners_${{ parameters.SparkVersion }}_${{ parameters.ScalaVersion }}-1.0.0.jar'
        versionOption: major
        packagePublishDescription: 'NHT Custom Log Analytic JARs'

    - task: UniversalPackages@0
      displayName: Universal Publish Spark-Listeners
      continueOnError: true
      inputs:
        command: 'publish'
        publishDirectory: '$(Pipeline.Workspace)/s/src/target'
        feedsToUsePublish: 'internal'
        vstsFeedPublish: '3c59b87f-2432-4abe-afde-e4027aeaadf8'
        vstsFeedPackagePublish: 'spark-listeners_${{ parameters.SparkVersion }}_${{ parameters.ScalaVersion }}-1.0.0'
        versionOption: major
        packagePublishDescription: 'NHT Custom Log Analytic JARs'

    - task: UniversalPackages@0
      displayName: Universal Publish Spark-Listeners-Loganalytics
      inputs:
        command: 'publish'
        publishDirectory: '$(Pipeline.Workspace)/src/target/spark-listeners-loganalytics_${{ parameters.SparkVersion }}_${{ parameters.ScalaVersion }}-1.0.0.jar'
        feedsToUsePublish: 'internal'
        vstsFeedPublish: '3c59b87f-2432-4abe-afde-e4027aeaadf8'
        vstsFeedPackagePublish: 'spark-listeners-loganalytics_${{ parameters.SparkVersion }}_${{ parameters.ScalaVersion }}-1.0.0.jar'
        versionOption: major
        packagePublishDescription: 'NHT Custom Log Analytic JARs'
